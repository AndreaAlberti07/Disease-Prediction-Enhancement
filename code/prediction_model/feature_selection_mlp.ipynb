{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-wise Feature selection\n",
    "Forward step-wise selection of the best features to use, following a greedy approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import clone\n",
    "from matplotlib import colors\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"features/\"\n",
    "filenames = [\"symptoms.npz\", \"betweennes.npz\", \"community_count.npz\", \"community_size.npz\", \"ks_level_1.npz\", \"ks_level_2.npz\"]\n",
    "names = [\"symptoms\", \"betweenness\", \"community_count\", \"community_size\", \"ks_level_1\", \"ks_level_2\"]\n",
    "sample_percentage = 0.1\n",
    "parameters = {\n",
    "    \"max_iter\": [1000],\n",
    "    'hidden_layer_sizes': [(500,)],\n",
    "    'alpha': [0.001],\n",
    "    'activation': ['relu'],\n",
    "}\n",
    "model = MLPClassifier(**parameters, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load features from .npz files\n",
    "labels = np.load(path + filenames[0])['y']\n",
    "num_samples = int(labels.shape[0] * sample_percentage)\n",
    "sampled_indices = np.random.choice(labels.shape[0], num_samples, replace=False)\n",
    "labels = labels[sampled_indices]\n",
    "features = []\n",
    "for filename in filenames:\n",
    "    file_path = path + filename\n",
    "    data = np.load(file_path)\n",
    "    feature_matrix = data['X']\n",
    "    feature_matrix = feature_matrix[sampled_indices, :]\n",
    "    features.append(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature selection and record accuracies\n",
    "num_features = len(features)\n",
    "remaining_features = list(range(num_features))\n",
    "already_used_features = []\n",
    "accuracies = []\n",
    "\n",
    "# Initial null model with the first feature\n",
    "X_train, X_test, y_train, y_test = train_test_split(features[0], labels, test_size=0.2, random_state=42)\n",
    "# Perform logistic regression and compute accuracy\n",
    "model_ = clone(model)\n",
    "model_.fit(X_train, y_train)\n",
    "y_pred = model_.predict(X_test)\n",
    "null_model_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Baseline model: accuracy = {null_model_accuracy*100:4.2f}.\")\n",
    "accuracies.append(null_model_accuracy)\n",
    "remaining_features.pop(0)\n",
    "already_used_features.append(0)\n",
    "\n",
    "# Feature selection iterations\n",
    "it = 0\n",
    "accuracy_matrix = np.zeros((num_features-1, num_features-1))\n",
    "while remaining_features:\n",
    "    best_accuracy = 0\n",
    "    best_feature = None\n",
    "\n",
    "    for feature_index in remaining_features:\n",
    "        current_features = already_used_features + [feature_index]\n",
    "        X = np.hstack([features[i] for i in current_features])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "        # Perform logistic regression and compute accuracy\n",
    "        model_ = clone(model)\n",
    "        model_.fit(X_train, y_train)\n",
    "        y_pred = model_.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        accuracy_matrix[it][feature_index-1] = accuracy\n",
    "        print(f\"Model [{it}][{feature_index}]: accuracy = {accuracy*100:4.2f}.\")\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_feature = feature_index\n",
    "\n",
    "    # Update lists\n",
    "    accuracies.append(best_accuracy)\n",
    "    remaining_features.remove(best_feature)\n",
    "    already_used_features.append(best_feature)\n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_used_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model accuracies with custom colormap\n",
    "norm = colors.Normalize(vmin=-null_model_accuracy, vmax=1-null_model_accuracy)\n",
    "cmap = plt.get_cmap('RdYlGn')\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(accuracy_matrix-null_model_accuracy, cmap=cmap, norm=norm)\n",
    "tick_marks = np.arange(num_features-1)\n",
    "reordered_names = [names[i] for i in already_used_features]\n",
    "plt.xticks(tick_marks, labels=names[1:], rotation='vertical', ha='center')  # Set custom tick marks\n",
    "plt.yticks(tick_marks, labels=reordered_names[:-1])\n",
    "ax = plt.gca()\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.xlabel(\"Features to be added\")\n",
    "plt.ylabel(\"Best previous feature\")\n",
    "\n",
    "# Add text with colored background based on the value\n",
    "for i in range(num_features-1):\n",
    "    for j in range(num_features-1):\n",
    "        val = accuracy_matrix[i, j]\n",
    "        color = cmap(norm(val-null_model_accuracy))\n",
    "        plt.text(j, i, f\"{val*100:4.2f}\", ha='center', va='center', color='red' if val == 0 else 'black', backgroundcolor=color)\n",
    "\n",
    "plt.title(f\"Accuracy of the partial models\\nBaseline model accuracy = {null_model_accuracy*100:4.2f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracies for each best model\n",
    "plt.plot(range(len(accuracies)), np.array(accuracies)*100, marker='o')\n",
    "plt.xlabel('Number of Metrics')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 100)\n",
    "plt.title('Accuracy vs. Number of Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection based on Commonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection based on a specific criterion\n",
    "\n",
    "# Compute the threshold\n",
    "threshold_feature = \"ks_level_2\"\n",
    "\n",
    "thr_data_unsampled = np.load(path+threshold_feature+\".npz\")\n",
    "thr_data = thr_data_unsampled['X'][sampled_indices, :]\n",
    "\n",
    "percentiles = np.percentile(np.mean(thr_data, axis=1), np.geomspace(50, 1e-6, 10), axis=0)\n",
    "\n",
    "used_features = copy.deepcopy([features[i] for i in already_used_features[:np.argmax(accuracies)]])\n",
    "\n",
    "accuracies_filt = []\n",
    "percentages = []\n",
    "for perc in percentiles:\n",
    "    filtered_coefficients = np.where(np.mean(thr_data, axis=0) > perc)[0]\n",
    "    if filtered_coefficients.size == 0:\n",
    "        continue\n",
    "    X = np.hstack([f[:, filtered_coefficients] for f in used_features])\n",
    "    data_percentage = filtered_coefficients.shape[0]/thr_data.shape[1]\n",
    "\n",
    "    # Perform logistic regression and compute accuracy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "    model_ = clone(model)\n",
    "    model_.fit(X_train, y_train)\n",
    "    y_pred = model_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy = {accuracy*100:4.2f}; retained features = {data_percentage*100:4.2f}%\")\n",
    "    accuracies_filt.append(accuracy)\n",
    "    percentages.append(data_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracies for each model\n",
    "plt.plot(np.array(percentages)*100, np.array(accuracies_filt)*100, marker='o')\n",
    "plt.axhline(y=np.max(accuracies)*100, color='r', linestyle='--', label='')\n",
    "plt.plot(100, np.max(accuracies)*100, color='r', marker='o')\n",
    "plt.xlabel('% of features retained')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 100)\n",
    "plt.xlim(10, 101)\n",
    "plt.title('Accuracy vs. Filtered features, based on '+threshold_feature)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection based on Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection based on a specific criterion\n",
    "\n",
    "# Compute the threshold\n",
    "threshold_feature1 = \"ks_level_1\"\n",
    "\n",
    "thr_data_unsampled1 = np.load(path+threshold_feature1+\".npz\")\n",
    "thr_data1 = thr_data_unsampled1['X'][sampled_indices, :]\n",
    "\n",
    "percentiles1 = np.percentile(np.mean(thr_data1, axis=1), np.geomspace(50, 1e-6, 10), axis=0)\n",
    "\n",
    "used_features1 = copy.deepcopy([features[i] for i in already_used_features[:np.argmax(accuracies)]])\n",
    "\n",
    "accuracies_filt1 = []\n",
    "percentages1 = []\n",
    "for perc in percentiles1:\n",
    "    filtered_coefficients = np.where(np.mean(thr_data1, axis=0) > perc)[0]\n",
    "    if filtered_coefficients.size == 0:\n",
    "        continue\n",
    "    X = np.hstack([f[:, filtered_coefficients] for f in used_features1])\n",
    "    data_percentage = filtered_coefficients.shape[0]/thr_data1.shape[1]\n",
    "\n",
    "    # Perform logistic regression and compute accuracy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "    model_ = clone(model)\n",
    "    model_.fit(X_train, y_train)\n",
    "    y_pred = model_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy = {accuracy*100:4.2f}; retained features = {data_percentage*100:4.2f}%\")\n",
    "    accuracies_filt1.append(accuracy)\n",
    "    percentages1.append(data_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracies for each model\n",
    "plt.plot(np.array(percentages1)*100, np.array(accuracies_filt1)*100, marker='o')\n",
    "plt.axhline(y=np.max(accuracies)*100, color='r', linestyle='--', label='')\n",
    "plt.plot(100, np.max(accuracies)*100, color='r', marker='o')\n",
    "plt.xlabel('% of features retained')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 100)\n",
    "plt.xlim(10, 101)\n",
    "plt.title('Accuracy vs. Filtered features, based on '+threshold_feature1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
